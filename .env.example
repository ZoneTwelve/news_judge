# Environment Configuration

# ================================
# OpenAI API Configuration
# ================================

# Required: Your OpenAI API key
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY="your-api-key-here"

# Optional: Custom OpenAI API Base URL
# Use this to connect to OpenAI-compatible services like:
# - Azure OpenAI: https://your-resource.openai.azure.com
# - LocalAI: http://localhost:8080/v1
# - Other OpenAI-compatible endpoints
# Leave commented to use official OpenAI API
# OPENAI_BASE_URL="https://api.openai.com/v1"

# Optional: Model to use for API calls
# Examples: gpt-3.5-turbo, gpt-4, gpt-4-turbo-preview
# For custom endpoints, use the model name supported by your service
# OPENAI_MODEL="gpt-3.5-turbo"

# Optional: Temperature setting for controlling randomness (0.0-2.0)
# Lower values (e.g., 0.0) make output more focused and deterministic
# Higher values (e.g., 1.0+) make output more creative and varied
# OPENAI_TEMPERATURE="0.0"

# Optional: Maximum tokens for API responses
# Controls the maximum length of generated responses
# OPENAI_MAX_TOKENS="2000"

# ================================
# Gradio Server Configuration
# ================================

# Optional: Port for Gradio demo interface (demo.py)
# GRADIO_SERVER_PORT="7860"

# Optional: Enable Gradio sharing (creates public URL)
# GRADIO_SHARE="false"

# ================================
# Logging Configuration
# ================================

# Optional: Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# LOG_LEVEL="INFO"
